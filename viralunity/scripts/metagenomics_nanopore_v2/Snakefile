##############################################
# Set helper functions and variables
##############################################

def get_exclude_taxids():
    """
    TaxIDs to exclude from classification outputs / krona inputs.
    - 9606: Homo sapiens
    - 0: unclassified
    """
    exclude = []
    if config.get("remove_human_reads", False):
        exclude.append("9606")
    if config.get("remove_unclassified_reads", False):
        exclude.append("0")
    return exclude

EXCLUDE_TAXIDS = get_exclude_taxids()

def get_final_input_fastq(wildcards):
    return config["output"] + f"host_filtered/{wildcards.sample}.filtered.fastq.gz"

host_filtering_enabled = config.get("host_reference", "NA") != "NA"

##############################################
# Establish all targets
##############################################

rule all:
    input:
        kraken2_reads_summary = (
            config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary.tsv"
            if config.get("run_kraken2_reads", False) else []
        ),

        kraken2_contigs_summary = (
            config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/kraken2_contigs_taxa_summary.tsv"
            if config.get("run_kraken2", False) and config.get("run_denovo_assembly", False) else []
        ),

        diamond_reads_summary = (
            config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary.tsv"
            if config.get("run_diamond_reads", False) else []
        ),

        diamond_contigs_summary = (
            config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary.tsv"
            if config.get("run_diamond", False) and config.get("run_denovo_assembly", False) else []
        ),

        kraken2_reads_RPM_summary = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.tsv"
            if config.get("run_kraken2_reads", False) else [],

        diamond_reads_RPM_summary = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.tsv"
            if config.get("run_diamond_reads", False) else [],

        diamond_contigs_RPM_summary = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.tsv"
            if config.get("run_diamond", False) and config.get("run_denovo_assembly", False) else [],

        kraken2_reads_RPM_summary_bleed = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.bleed.tsv"
            if config.get("run_kraken2_reads", False) else [],

        diamond_reads_RPM_summary_bleed = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.bleed.tsv"
            if config.get("run_diamond_reads", False) else [],
        
        diamond_contigs_RPM_summary_bleed = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.bleed.tsv"
            if config.get("run_diamond", False) and config.get("run_denovo_assembly", False) else [],

        kraken2_reads_RPM_summary_neg = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.bleed.neg.tsv"
            if config.get("run_kraken2_reads", False) else [],

        diamond_reads_RPM_summary_neg = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.bleed.neg.tsv"
            if config.get("run_diamond_reads", False) else [],

        diamond_contigs_RPM_summary_neg = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.bleed.neg.tsv"
            if config.get("run_diamond", False) and config.get("run_denovo_assembly", False) else []

##############################################
# Dehosting
##############################################

if host_filtering_enabled:

    rule index_host_genome:
        input:
            fasta = config["host_reference"]
        output:
            index = config["host_reference"] + ".mmi"
        threads: config["threads"]
        log:
            config['output'] + "logs/remove_host/host_genome_indexing.log"
        benchmark:
            config['output'] + "logs/remove_host/host_genome_indexing.benchmark.txt"
        shell:
            r"""
            set -euo pipefail
            minimap2 -d {output.index} {input.fasta} > {log} 2>&1
            """

    rule remove_host_reads:
        input:
            reads = lambda wildcards: config["samples"][wildcards.sample],
            index = config["host_reference"] + ".mmi"
        output:
            filtered = config["output"] + "host_filtered/{sample}.filtered.fastq.gz"
        threads: config["threads"]
        log:
            config["output"] + "logs/remove_host/{sample}.log"
        benchmark:
            config["output"] + "logs/remove_host/{sample}.benchmark.txt"
        shell:
            r"""
            set -euo pipefail

            mkdir -p "$(dirname {output.filtered})" "$(dirname {log})"

            minimap2 -t {threads} -ax map-ont "{input.index}" "{input.reads}" 2>> "{log}" \
            | samtools view -@ {threads} -u -f 4 - 2>> "{log}" \
            | samtools fastq -@ {threads} - 2>> "{log}" \
            | gzip -c > "{output.filtered}"

            unc_size="$(gzip -l "{output.filtered}" | awk 'NR==2 {{print $2}}')"
            if [[ "${{unc_size}}" == "0" ]]; then
                echo "WARNING: No reads remained after host filtering for sample {wildcards.sample}." >> "{log}"
            fi
            """

else:

    rule remove_host_reads:
        input:
            reads = lambda wildcards: config["samples"][wildcards.sample],
        output:
            filtered = config["output"] + "host_filtered/{sample}.filtered.fastq.gz"
        log:
            config["output"] + "logs/remove_host/{sample}.log"
        benchmark:
            config["output"] + "logs/remove_host/{sample}.benchmark.txt"
        shell:
            r"""
            set -euo pipefail
            mkdir -p "$(dirname {output.filtered})" "$(dirname {log})"

            if [[ "{input.reads}" == *.gz ]]; then
                cp -f "{input.reads}" "{output.filtered}"
            else
                gzip -c "{input.reads}" > "{output.filtered}"
            fi

            echo "No host genome provided â€” skipping host read removal." > "{log}"
            """

##############################################
# Reads analyses
##############################################

# Kraken2 on reads

rule run_kraken2_reads:
    input:
        fastq = get_final_input_fastq
    output:
        report = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.report.txt",
        outfile = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.output.txt",
    threads: config["threads"]
    params:
        database = config['kraken2_database']
    log:
        config['output'] + "logs/kraken2_reads/{sample}.log"
    benchmark:
        config['output'] + "logs/kraken2_reads/{sample}.benchmark.txt"
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output.report})
        mkdir -p $(dirname {log})

        unc_size="$(gzip -l "{input.fastq}" | awk 'NR==2 {{print $2}}')"
        if [[ "${{unc_size}}" == "0" ]]; then
            echo "WARNING: {input.fastq} missing or empty. Creating dummy Kraken2 READS outputs." > {log}
            : > {output.report}
            : > {output.outfile}
        else
            kraken2 --db {params.database} --threads {threads} --report-minimizer-data \
                --minimum-hit-group 3 --report {output.report} \
                --output {output.outfile} {input.fastq} 2> {log}
        fi
        """

rule create_krona_input_from_kraken2_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.output.txt"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.output.krona.txt"
    params:
        keep_columns = [1, 2],
        taxid_column = 1,
        exclude_taxids = EXCLUDE_TAXIDS
    script:
        "scripts/filter_taxids.py"

rule create_krona_report_from_kraken2_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.output.krona.txt"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/reports/{sample}.output.krona.html"
    params:
        krona_database = config['krona_database']
    log:
        config['output'] + "logs/krona_kraken2_reads/{sample}.log"
    benchmark:
        config['output'] + "logs/krona_kraken2_reads/{sample}.benchmark.txt"
    shell:
        r"""
        set -euo pipefail
        if [ -s {input} ]; then
            ktImportTaxonomy {input} -tax {params.krona_database} -o {output} 2> {log}
        else
            echo "Empty krona input file detected (kraken2 reads). No visualization will be created (only a dummy file)." > {log}
            : > {output}
        fi
        """

rule summarize_taxa_kraken2_reads:
    input:
        krona = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/results/{sample}.output.krona.txt",
        plot = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/reports/{sample}.output.krona.html"
    output:
        temp(config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/summary/{sample}.taxa.tsv")
    params:
        taxdump = config["taxdump"],
        tool = "kraken2",
        mode = "reads",
        sample = "{sample}"
    script:
        "scripts/summarize_krona_taxa.py"

rule summarize_taxa_kraken2_reads_all:
    input:
        expand(
            config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/summary/{sample}.taxa.tsv",
            sample=config["samples"]
        )
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary.tsv"
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output})

        # Find first non-empty input to extract header
        header_file=""
        for f in {input}; do
            if [ -s "$f" ]; then
                header_file="$f"
                break
            fi
        done

        # Write header
        if [ -n "$header_file" ]; then
            head -n 1 "$header_file" > {output}
        else
            echo -e "sample\ttool\tmode\trank\ttaxid\tname\tcount\tpercent\tsource" > {output}
        fi

        # Append rows
        for f in {input}; do
            if [ -s "$f" ]; then
                tail -n +2 "$f" >> {output}
            fi
        done
        """

rule add_RPM_to_kraken2_reads_summary:
    input:
        aggregated_summary = config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.tsv"
    params:
        samples = config["samples"],
        reads_col = "count"
    script:
        "scripts/add_RPM_to_summary.py"

rule apply_bleed_filter_kraken2_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.bleed.tsv"
    params:
        fraction = config.get("bleed_fraction", 0.005),
        rpm_floor = 1.0,
        rpm_col = "rpm",
    script:
        "scripts/apply_max_rpm_bleed_filter.py"

rule apply_negative_background_kraken2_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.bleed.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_reads/kraken2_reads_taxa_summary_RPM.bleed.neg.tsv"
    params:
        negatives = config.get("negative_controls", []),
        count_col = "count",
        p_threshold = config.get("negative_p_threshold", 0.01)
    script:
        "scripts/apply_negative_background_filter.py"

# DIAMOND on reads

rule create_diamond_db:
    input:
        config['diamond_database']
    output:
        config['diamond_database'] + '.dmnd'
    log:
        config['output'] + 'logs/diamond/diamond_makedb.log'
    benchmark:
        config['output'] + 'logs/diamond/diamond_makedb.benchmark.log'
    shell:
        r"""
        set -euo pipefail
        if [ "{input}" = "NA" ] || [ -z "{input}" ]; then
            echo "DIAMOND database not provided (diamond_database=NA). This rule should not run unless DIAMOND is enabled." > {log}
            exit 1
        fi
        diamond makedb --in {input} --db {output} 2> {log}
        """

rule run_diamond_reads:
    input:
        fastq = get_final_input_fastq,
        db = config['diamond_database'] + ".dmnd"
    output:
        tsv = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.tsv"
    threads: config["threads"]
    log:
        config['output'] + "logs/diamond_reads/{sample}.log"
    benchmark:
        config['output'] + "logs/diamond_reads/{sample}.benchmark.txt"
    params:
        sensitivity = config['diamond_sensitivity'],
        evalue = config['evalue']
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output.tsv})
        mkdir -p $(dirname {log})

        unc_size="$(gzip -l "{input.fastq}" | awk 'NR==2 {{print $2}}')"
        if [[ "${{unc_size}}" == "0" ]]; then
            echo "WARNING: {input.fastq} missing or empty. Creating dummy DIAMOND READS output." > {log}
            : > {output.tsv}
        else
            diamond blastx \
                --db {input.db} \
                --query {input.fastq} \
                --out {output.tsv} \
                --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore \
                --max-target-seqs 1 \
                --evalue {params.evalue} \
                --{params.sensitivity} \
                --threads {threads} 2> {log}
        fi
        """

rule create_krona_input_from_diamond_reads:
    input:
        diamond = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.tsv",
        fastq = rules.run_diamond_reads.input.fastq,
        assembly = config["assembly_summary"]
    output:
        krona_input = temp(config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.krona_input.temp.tsv")
    params:
        data_format = "fastq"
    script:
        "scripts/convert_diamond_output_to_krona_input.py"

rule filter_krona_input_from_diamond_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.krona_input.temp.tsv"
    output:
        config["output"] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.supported.krona_input.tsv"
    params:
        taxid_column = 1,
        exclude_taxids = EXCLUDE_TAXIDS
    script:
        "scripts/filter_taxids.py"

rule create_krona_report_diamond_reads:
    input:
        config["output"] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.supported.krona_input.tsv"
    output:
        config["output"] + "metagenomics/taxonomic_assignments/diamond_reads/reports/{sample}.diamond.krona.html"
    params:
        krona_database = config['krona_database']
    log:
        config['output'] + "logs/krona_diamond_reads/{sample}.log"
    benchmark:
        config['output'] + "logs/krona_diamond_reads/{sample}.benchmark.txt"
    shell:
        r"""
        set -euo pipefail
        if [ -s {input} ]; then
            ktImportTaxonomy {input} -tax {params.krona_database} -o {output} 2> {log}
        else
            echo "Empty krona input file detected (diamond reads). No visualization will be created (only a dummy file)." > {log}
            : > {output}
        fi
        """

rule summarize_taxa_diamond_reads:
    input:
        krona = config["output"] + "metagenomics/taxonomic_assignments/diamond_reads/results/{sample}.diamond.supported.krona_input.tsv",
        plot = config["output"] + "metagenomics/taxonomic_assignments/diamond_reads/reports/{sample}.diamond.krona.html"
    output:
        temp(config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/summary/{sample}.taxa.tsv")
    params:
        taxdump = config["taxdump"],
        tool = "diamond",
        mode = "reads",
        sample = "{sample}"
    script:
        "scripts/summarize_krona_taxa.py"

rule summarize_taxa_diamond_reads_all:
    input:
        expand(
            config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/summary/{sample}.taxa.tsv",
            sample=config["samples"]
        )
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary.tsv"
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output})

        # Find first non-empty input to extract header
        header_file=""
        for f in {input}; do
            if [ -s "$f" ]; then
                header_file="$f"
                break
            fi
        done

        # Write header
        if [ -n "$header_file" ]; then
            head -n 1 "$header_file" > {output}
        else
            echo -e "sample\ttool\tmode\trank\ttaxid\tname\tcount\tpercent\tsource" > {output}
        fi

        # Append rows
        for f in {input}; do
            if [ -s "$f" ]; then
                tail -n +2 "$f" >> {output}
            fi
        done
        """

rule add_RPM_to_diamond_reads_summary:
    input:
        aggregated_summary = config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.tsv"
    params:
        samples = config["samples"],
        reads_col = "count"
    script:
        "scripts/add_RPM_to_summary.py"

rule apply_bleed_filter_diamond_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.bleed.tsv"
    params:
        fraction = config.get("bleed_fraction", 0.005),
        rpm_floor = 1.0,
        rpm_col = "rpm",
    script:
        "scripts/apply_max_rpm_bleed_filter.py"

rule apply_negative_background_diamond_reads:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.bleed.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_reads/diamond_reads_taxa_summary_RPM.bleed.neg.tsv"
    params:
        negatives = config.get("negative_controls", []),
        count_col = "count",
        p_threshold = config.get("negative_p_threshold", 0.01)
    script:
        "scripts/apply_negative_background_filter.py"

##############################################
# De novo Assembly with MEGAHIT
##############################################

rule fastq_for_assembly:
    input:
        fastq = get_final_input_fastq
    output:
        fq = temp("/tmp/viralunity_megahit_inputs/{sample}.fastq")
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {output.fq})"
        if [[ "{input.fastq}" == *.gz ]]; then
            gzip -cd "{input.fastq}" > "{output.fq}"
        else
            cp -f "{input.fastq}" "{output.fq}"
        fi
        """

rule run_megahit:
    input:
        fastq = rules.fastq_for_assembly.output.fq
    output:
        contigs = config['output'] + "denovo_assembly/megahit/{sample}/final.contigs.fa"
    threads: config["threads"]
    log:
        config['output'] + "logs/megahit/{sample}.log"
    params:
        workdir = "/tmp/viralunity_megahit/{sample}"
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname {log})" "$(dirname {output.contigs})"
        rm -rf "{params.workdir}"
        mkdir -p "{params.workdir}"

        if [[ ! -s "{input.fastq}" ]]; then
            echo "WARNING: Input FASTQ is empty for sample {wildcards.sample}. Skipping MEGAHIT." > "{log}"
            : > "{output.contigs}"
            exit 0
        fi

        megahit -r "{input.fastq}" -o "{params.workdir}/out" --num-cpu-threads {threads} > "{log}" 2>&1
        cp -f "{params.workdir}/out/final.contigs.fa" "{output.contigs}"
        rm -rf "{params.workdir}"
        """


##############################################
# Contigs analyses
##############################################

# Kraken2 on contigs

rule run_kraken2_contigs:
    input:
        fasta = rules.run_megahit.output.contigs
    output:
        report = config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.report.txt",
        outfile = config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.output.txt",
    threads: config["threads"]
    params:
        database = config['kraken2_database']
    log:
        config['output'] + "logs/kraken2_contigs/{sample}.log"
    benchmark:
        config['output'] + "logs/kraken2_contigs/{sample}.benchmark.txt"
    shell:
        """
        if [ ! -s {input.fasta} ]; then
            echo "WARNING: {input.fasta} missing or empty. Creating dummy Kraken2 outputs." > {log}
            touch {output.report}
            touch {output.outfile}
        else
            kraken2 --db {params.database} --threads {threads} --report-minimizer-data \
                --minimum-hit-group 3 --report {output.report} \
                --output {output.outfile} {input.fasta} 2> {log}
        fi
        """

rule create_krona_input_from_kraken2_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.output.txt"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.output.krona.txt"
    params:
        keep_columns = [1, 2],
        taxid_column = 1,
        exclude_taxids = EXCLUDE_TAXIDS
    script:
        "scripts/filter_taxids.py"

rule create_krona_report_from_kraken2_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.output.krona.txt"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/reports/{sample}.output.krona.html"
    params:
        krona_database = config['krona_database']
    log:
        config['output'] + "logs/krona_kraken2_contigs/{sample}.log"
    benchmark:
        config['output'] + "logs/krona_kraken2_contigs/{sample}.benchmark.txt"
    shell:
        """
        if [ -s {input} ]; then
            ktImportTaxonomy {input} -tax {params.krona_database} -o {output} 2> {log};
        else
            echo "Empty krona input file detected (kraken2 contigs). No visualization will be created (only a dummy file)." > {log};
            touch {output};
        fi
        """

rule summarize_taxa_kraken2_contigs:
    input:
        krona = config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/results/{sample}.output.krona.txt",
        plot = config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/reports/{sample}.output.krona.html"
    output:
        temp(config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/summary/{sample}.taxa.tsv")
    params:
        taxdump = config["taxdump"],
        tool = "kraken2",
        mode = "contigs",
        sample = "{sample}"
    script:
        "scripts/summarize_krona_taxa.py"

rule summarize_taxa_kraken2_contigs_all:
    input:
        expand(
            config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/summary/{sample}.taxa.tsv",
            sample=config["samples"]
        )
    output:
        config['output'] + "metagenomics/taxonomic_assignments/kraken2_contigs/kraken2_contigs_taxa_summary.tsv"
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output})

        # Find first non-empty input to extract header
        header_file=""
        for f in {input}; do
            if [ -s "$f" ]; then
                header_file="$f"
                break
            fi
        done

        # Write header
        if [ -n "$header_file" ]; then
            head -n 1 "$header_file" > {output}
        else
            echo -e "sample\ttool\tmode\trank\ttaxid\tname\tcount\tpercent\tsource" > {output}
        fi

        # Append rows
        for f in {input}; do
            if [ -s "$f" ]; then
                tail -n +2 "$f" >> {output}
            fi
        done
        """

# Diamond on contigs

rule run_diamond_contigs:
    input:
        fasta = rules.run_megahit.output.contigs,
        db = config['diamond_database'] + '.dmnd'
    output:
        tsv = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.tsv"
    threads: config["threads"]
    log:
        config['output'] + "logs/diamond_contigs/{sample}.log"
    benchmark:
        config['output'] + "logs/diamond_contigs/{sample}.benchmark.txt"
    params:
        sensitivity = config['diamond_sensitivity'],
        evalue = config['evalue']
    shell:
        """
        if [ ! -s {input.fasta} ]; then
            echo "WARNING: {input.fasta} missing or empty. Creating dummy DIAMOND output." > {log};
            touch {output.tsv};
        else
            diamond blastx --db {input.db} --query {input.fasta} \
                --out {output.tsv} --outfmt 6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qlen slen qseq qseq_translated full_qseq sseq full_sseq \
                --max-target-seqs 1 --evalue {params.evalue} \
                --{params.sensitivity} --threads {threads} 2> {log}
        fi
        """

rule trim_diamond_contig_regions:
    input:
        fasta   = rules.run_megahit.output.contigs,
        tsv     = rules.run_diamond_contigs.output.tsv
    output:
        trimmed = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.trimmed.fa"
    params:
        min_len = 1
    log:
        config['output'] + "logs/trim_diamond_contigs/{sample}.log"
    benchmark:
        config['output'] + "logs/trim_diamond_contigs/{sample}.benchmark.txt"
    script:
        "scripts/parse_diamond_trim_fasta.py"

rule medaka_consensus_trimmed:
    input:
        reads   = config["output"] + "host_filtered/{sample}.filtered.fastq.gz",
        contigs = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.trimmed.fa"
    output:
        polished_contigs = config["output"] + "medaka/{sample}/viral_consensus.fasta"
    params:
        outdir = config["output"] + "medaka/{sample}/"
    threads: config["threads"]
    log:
        config["output"] + "logs/medaka_consensus_trimmed/{sample}.log"
    benchmark:
        config["output"] + "logs/medaka_consensus_trimmed/{sample}.benchmark.txt"
    shell:
        r"""
        # If the trimmed FASTA is empty, create an empty polished file and exit gracefully
        if [ ! -s {input.contigs} ]; then
            echo "No viral regions to polish for sample {wildcards.sample}" > {log}
            mkdir -p {params.outdir}
            touch {output.polished_contigs}
        else
            medaka_consensus \
                -i {input.reads} \
                -d {input.contigs} \
                -o {params.outdir} \
                -g -r 'N' \
                -t {threads} &> {log}
            # Medaka writes consensus to {params.outdir}/consensus.fasta
            mv {params.outdir}/consensus.fasta {output.polished_contigs}
        fi
        """

rule bam_sort_index_idxstats:
    input:
        fasta = config["output"] + "medaka/{sample}/viral_consensus.fasta",
    output:
        sorted_bam = config["output"] + "medaka/{sample}/calls_to_draft.sorted.bam",
        bai        = config["output"] + "medaka/{sample}/calls_to_draft.sorted.bam.bai",
        idxstats   = config["output"] + "medaka/{sample}/calls_to_draft.idxstats.tsv",
        idxstats_filtered = config["output"] + "medaka/{sample}/calls_to_draft.idxstats.filtered.tsv"        
    threads: config["threads"]
    log:
        config["output"] + "logs/bam_idxstats/{sample}.log"
    benchmark:
        config["output"] + "logs/bam_idxstats/{sample}.benchmark.txt"
    params:
        bam = config["output"] + "medaka/{sample}/calls_to_draft.bam"
    shell:
        r"""
        set -euo pipefail

        if [ ! -s {params.bam} ]; then
            echo "No viral contigs were polished - {wildcards.sample}" > {log}
            echo "Creating empty bam, bai, idxstats files" > {log}
            touch {output.sorted_bam}
            touch {output.bai}         
            touch {output.idxstats}
            touch {output.idxstats_filtered}             
        else
            # 1. sort
            samtools sort -@ {threads} -o {output.sorted_bam} {params.bam} 2>>{log}

            # 2. index
            samtools index -@ {threads} {output.sorted_bam} 2>>{log}

            # 3. per-reference read counts
            samtools idxstats {output.sorted_bam} > {output.idxstats} 2>>{log}

            # 4. Get version of idxstats with only contigs presenting mapped reads
            awk '$3 > 0 && $1 != "*"' {output.idxstats} > {output.idxstats_filtered} 2>>{log}
        fi

        
        """

rule diamond_filter_by_idxstats:
    input:
        diamond  = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.tsv",
        idxstats = config["output"] + "medaka/{sample}/calls_to_draft.idxstats.tsv"
    output:
        filtered = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.tsv"
    params:
        min_mapped = 1
    log:
        config["output"] + "logs/diamond_filter/{sample}.log"
    benchmark:
        config["output"] + "logs/diamond_filter/{sample}.benchmark.txt"
    script:
        "scripts/filter_diamond_by_idxstats.py"

rule create_krona_input_from_diamond_contigs:
    input:
        diamond = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.tsv",
        fasta = rules.run_megahit.output.contigs,
        assembly = config["assembly_summary"]
    output:
        krona_input = temp(config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.krona_input.temp.tsv")
    params:
        data_format = "fasta"
    script:
        "scripts/convert_diamond_output_to_krona_input.py"

rule filter_krona_input_from_diamond_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.krona_input.temp.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.krona_input.tsv"
    params:
        taxid_column = 1,
        exclude_taxids = EXCLUDE_TAXIDS
    script:
        "scripts/filter_taxids.py"

rule create_krona_report_diamond_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.krona_input.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/reports/{sample}.diamond.supported.krona.html"
    params:
        krona_database = config['krona_database']
    log:
        config['output'] + "logs/krona_diamond_contigs/{sample}.log"
    benchmark:
        config['output'] + "logs/krona_diamond_contigs/{sample}.benchmark.txt"
    shell:
        """
        if [ -s {input} ]; then
            ktImportTaxonomy {input} -tax {params.krona_database} -o {output} 2> {log};
        else
            echo "Empty krona input file detected (diamond contigs). No visualization will be created (only a dummy file)." > {log};
            touch {output};
        fi
        """

rule annotate_diamond_taxonomy:
    input:
        diamond   = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.tsv",
        assembly  = config['assembly_summary']
    output:
        annotated = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.tax.tsv"
    log:
        config["output"] + "logs/annotate_tax/{sample}.log"
    benchmark:
        config["output"] + "logs/annotate_tax/{sample}.benchmark.txt"
    params:
        taxdump = config['taxdump']
    script:
        "scripts/annotate_diamond_taxonomy.py"

rule summarize_taxa_diamond_contigs:
    input:
        krona = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.krona_input.tsv",
        plot = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/reports/{sample}.diamond.supported.krona.html",
        annotated = config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/results/{sample}.diamond.supported.tax.tsv"
    output:
        config["output"] + "metagenomics/taxonomic_assignments/diamond_contigs/summary/{sample}.taxa.tsv"
    params:
        taxdump = config["taxdump"],
        tool = "diamond",
        mode = "contigs",
        sample = "{sample}"
    script:
        "scripts/summarize_krona_taxa.py"

rule summarize_taxa_diamond_contigs_all:
    input:
        expand(
            config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/summary/{sample}.taxa.tsv",
            sample=config["samples"]
        )
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary.tsv"
    shell:
        r"""
        set -euo pipefail
        mkdir -p $(dirname {output})

        # Find first non-empty input to extract header
        header_file=""
        for f in {input}; do
            if [ -s "$f" ]; then
                header_file="$f"
                break
            fi
        done

        # Write header
        if [ -n "$header_file" ]; then
            head -n 1 "$header_file" > {output}
        else
            echo -e "sample\ttool\tmode\trank\ttaxid\tname\tcount\tpercent\tsource" > {output}
        fi

        # Append rows
        for f in {input}; do
            if [ -s "$f" ]; then
                tail -n +2 "$f" >> {output}
            fi
        done
        """

rule add_RPM_to_diamond_contigs_summary:
    input:
        aggregated_summary = config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.tsv"
    params:
        samples = config["samples"],
        reads_col = "mapped_reads"
    script:
        "scripts/add_RPM_to_summary.py"

rule apply_bleed_filter_diamond_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.bleed.tsv"
    params:
        fraction = config.get("bleed_fraction", 0.005),
        rpm_floor = 1.0,
        rpm_col = "rpm",
    script:
        "scripts/apply_max_rpm_bleed_filter.py"

rule apply_negative_background_diamond_contigs:
    input:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.bleed.tsv"
    output:
        config['output'] + "metagenomics/taxonomic_assignments/diamond_contigs/diamond_contigs_taxa_summary_RPM.bleed.neg.tsv"
    params:
        negatives = config.get("negative_controls", []),   # list like ["NEG01","NEG02"]
        count_col = "mapped_reads",
        p_threshold = config.get("negative_p_threshold", 0.01)
    script:
        "scripts/apply_negative_background_filter.py"
