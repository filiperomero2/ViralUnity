# ViralUnity Metagenomics Filtering Framework

This document describes the **post-processing filtering framework** implemented in the ViralUnity metagenomics pipeline. These filters are designed to improve robustness, interpretability, and reproducibility of viral detections by explicitly accounting for sequencing depth, run-wide bleed-through, and background signal observed in negative controls.

The filtering logic is implemented as **independent post-processing steps**, downstream of taxonomic assignment, and applies uniformly across tools (Kraken2, DIAMOND), modes (reads, contigs), and taxonomic ranks.

---

## Design principles

The filtering system follows a few core principles:

* **Post-processing only**: No reads or contigs are removed upstream. All filters operate on summary tables.
* **Transparency**: All intermediate quantities (RPM, thresholds, p-values) are explicitly reported in output tables.
* **Tool-agnostic**: The same logic applies to Kraken2 and DIAMOND outputs.
* **Configurable but reproducible**: All thresholds are configurable via CLI and stored in the run config file.
* **Fail-safe defaults**: If no negative controls are provided, negative-control filtering becomes a no-op.

---

## Summary tables and inputs

Filtering operates on **taxonomic summary TSVs** generated by ViralUnity. These summaries must include:

* `sample` – canonical sample ID (e.g. `sample-barcode05`)
* `rank` – taxonomic rank (family, genus, species, etc.)
* `taxid` – NCBI taxonomic identifier
* A **count column**:

  * Reads summaries: `count` (number of assigned reads)
  * Contigs summaries: `mapped_reads` (number of reads remapped to contigs)

Raw read counts per sample are obtained from the **raw FASTQ files** and added to the summaries during post-processing.

---

## 1. RPM normalization

### Motivation

Sequencing depth varies across samples. Raw counts are therefore not directly comparable. ViralUnity normalizes all detections using **Reads Per Million raw reads (RPM)**.

### Definition

For each taxon in a sample:

```
RPM = (reads_for_taxon / total_raw_reads) × 1e6
```

Where:

* `reads_for_taxon` = `count` (reads mode) or `mapped_reads` (contigs mode)
* `total_raw_reads` = number of reads in the original raw FASTQ

### Output columns added

* `total_reads`
* `rpm`

RPM is used for reporting and for downstream bleed-through filtering.

---

## 2. Max-RPM bleed-through filter

### Motivation

Index hopping, barcode bleed-through, and cross-sample contamination often manifest as **low-level detections of taxa that are highly abundant in another sample from the same run**.

The max-RPM bleed-through filter removes detections that are inconsistent with run-wide abundance patterns.

### Concept

For each taxon (defined by tool, mode, rank, taxid):

1. Compute the **maximum RPM** observed across all samples in the run:

```
max_rpm = max(RPM across samples)
```

2. Define a minimum acceptable RPM as a fraction of that maximum:

```
bleed_threshold = fraction × max_rpm
```

3. A detection passes the bleed filter if:

```
RPM ≥ bleed_threshold
```

### Default parameter

* `fraction = 0.005` (0.5% of the run-wide maximum)

### Safeguard for weak taxa

If `max_rpm` is very small (default `< 1 RPM`), the bleed filter is **not applied** for that taxon to avoid unstable thresholds.

### Output columns added

* `max_rpm`
* `bleed_threshold`
* `bleed_applied` (boolean)
* `bleed_pass` (boolean)

No rows are removed; downstream steps may filter on `bleed_pass`.

---

## 3. Negative-control background filter

### Motivation

Some taxa appear consistently at low levels due to:

* reagent contamination
* laboratory background
* systematic misclassification

Negative controls provide an empirical estimate of this background signal.

### Scope

This filter is **only applied when negative controls are provided** via the CLI/config. If no negative controls are defined, the filter becomes a no-op.

### Background model

For each taxon and category (tool/mode/rank):

* Let `b_t` = total reads assigned to the taxon across all negative controls
* Let `B` = total raw reads across all negative controls

Define the background rate:

```
λ_t = b_t / B
```

For a sample `s` with `N_s` raw reads, the expected background count is:

```
μ_s,t = λ_t × N_s
```

### Statistical test

Observed count `c_s,t` is tested against a Poisson background model:

```
X ~ Poisson(μ_s,t)
```

Compute the one-sided tail probability:

```
p = P(X ≥ c_s,t)
```

### Decision rule

A detection passes the negative-control filter if:

```
p < p_threshold
```

### Default parameter

* `p_threshold = 0.01`

### Taxa absent from negatives

If a taxon is **never observed in negative controls**, it is **not evaluated** by this filter:

* `neg_evaluated = False`
* `p_bg`, `mu_bg`, `neg_pass` are reported as `NA`

This avoids introducing priors or pseudocounts and keeps the filter strictly empirical.

### Output columns added

* `neg_controls_used`
* `neg_b_t`
* `neg_B`
* `lambda_bg`
* `mu_bg`
* `p_bg`
* `neg_evaluated`
* `neg_pass`

---

## Configuration and CLI options

The filtering behavior is fully configurable via the ViralUnity CLI and recorded in the generated config file.

### CLI flags

```
--bleed-fraction FLOAT        Fraction of max RPM used for bleed filtering (default: 0.005)
--negative-controls STRING   Comma-separated sample IDs to use as negative controls
--negative-p-threshold FLOAT P-value threshold for negative background filter (default: 0.01)
```

### Config file keys

```yaml
bleed_fraction: 0.005
negative_controls:
  - sample-barcode09_sampled10percent
negative_p_threshold: 0.01
```

---

## Recommended interpretation strategy

The filters are intentionally orthogonal and should be interpreted together:

* **RPM** – signal strength normalized by sequencing depth
* **Bleed filter** – consistency with run-wide abundance patterns
* **Negative filter** – consistency with empirical background noise

A common downstream strategy is to define confidence tiers, for example:

* **High confidence**: `bleed_pass == True` AND (`neg_pass == True` OR `neg_evaluated == False`)
* **Moderate confidence**: `bleed_pass == True` but `neg_pass == False`
* **Low confidence**: `bleed_pass == False`

Exact tiering logic is intentionally left to the user to preserve flexibility.

---

## Summary

This filtering framework provides a principled, modular approach to improving viral metagenomics results in ViralUnity. By combining depth normalization, run-aware filtering, and empirical background modeling, it reduces false positives while preserving transparency and reproducibility.
